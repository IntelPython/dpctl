.. _user_manual_intro:

Introduction
------------

The Data Parallel Control (dpctl) package enables Python application developers
and extension developers to access a data-parallel computing resource or XPU
available on a modern heterogeneous system. The "X" in XPU can stand for
a diverse range of compute architectures such as a CPU, GPU, FPGA, *etc.*, and
can be tailored to the needs of an application. Dpctl's objective is to provide
a Python runtime to control or to manage an XPU from any Python application or
library, without the need for other Python packages to develop such a runtime
themselves. The runtime is built on top of the C++ SYCL standard and is
envisioned to be both vendor and architecture agnostic. If the underlying SYCL
runtime supports a type of architecture, the dpctl runtime will allow managing
that architecture from Python.

In its current form, dpctl relies on certain DPC++ extensions of SYCL standard.
Moreover, the binary distribution of dpctl uses the proprietary Intel(R) oneAPI
DPC++ runtime bundled as part of oneAPI and supports Intel XPU devices only.
However, dpctl is compatible with the runtime of open-source DPC++ sycl bundle
that can be compiled to support a wide range of architectures including CUDA,
AMD ROC, and HIP.

The user guide introduces the core features of dpctl and the underlying
concepts. The guide is meant primarily for users of the Python package. Library
and native extension developers should refer to the programmer's guide.

Basic Concepts
--------------

Every program starts by running on a **host**, and most of the lines
of code in a program, in particular lines of code implementing the
Python interpreter itself, are usually for the host. Hosts are
customarily CPUs.

Host connected to one or more **devices** (XPUs) programmable with a
specific driver is referred to as a **platform**. These devices can
have different architectures (CPUs, GPUs, FPGA, ASICs, DSP), but can
be programmed using the same unified programming model, `oneAPI`_ .

Note that the same physical hardware (say, a GPU) may be reflected as two
separate devices if they can be programmed by more than one driver,
e.g. one can encounter an OpenCL GPU device and a Level-Zero GPU
device. Heterogeneous computing refers to using multiple devices in a
program.

**Context** holds run-time information needed to operate on a device
or a group of devices, and a **queue** holds command groups to be
executed on the associated device.

Data parallelism enables access to parallel resources in a modern
heterogeous system.

.. todo::

    #. Introduce the basic concepts of Platforms, Devices, Contexts, Queues,
       Events, and USM.
    #. Introduce common terms: XPU, host.
    #. Add citations/references

.. Go over dpctl and dpctl tensor
